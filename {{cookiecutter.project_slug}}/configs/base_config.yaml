dataset: null

# Use AutoTrainer in conjunction with lib.model_extra.outputs.MultiHead
# and define the appropriate losses based on the head name
trainer: auto

run_id: 1

evaluators:
  - name: my_evaluator
    args:
      solution: 42

seed: -1 # no seed
epochs: 300
batch_size: 512
eval_batch_size: ${batch_size}

accumulation_steps: 1
clip_grad_norm: 1
max_grad_norm: 1.5
eval_every: 1
log_every: 5

model_checkpoint:
  save_model: 1
  override_checkpoints: 0
  monitor_quantity: <TODO>
  direction: up

scheduler_args:
  start_epoch: 0
  end_epoch: 300
  base_lr: 0.0001
  max_lr:  0.001
  mode: triangular
  step_size_up: 10
  step_size_down: 10

model: null
model_args:
  embedding_size: null
